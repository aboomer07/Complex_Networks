{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation and Analysis of Diffusion of Microfinance Data\n",
    "\n",
    "## Explanation and Sources\n",
    "*All data comes from the Harvard Dataverse website. The paper is cited below:*\n",
    "\n",
    "*Banerjee, Abhijit; Chandrasekhar, Arun G.; Duflo, Esther; Jackson, Matthew O., 2013, \"The Diffusion of Microfinance\", hdl:1902.1/21538, Harvard Dataverse, V9*\n",
    "\n",
    "**The paper studies how microfinance is diffused through social networks within villages in rural India. People's everyday activity's and interactions were coded into adjacency matrices so that their interactions can be studied and analyzed.**\n",
    "\n",
    "The notebook below is, for now, an exploratory analysis of this data. I start off by taking the large number of files (75 villages, several interaction types, and Person/House type, and storing all these files into dictionaries of dataframes that can be called by their adjusted filenames. This helped with organization, as I also built a dataframe of file names corresponding to the village, activity, and type I wanted to look at.\n",
    "\n",
    "The exploration so far, which I am working on finishing, involves calculating a variety of complex network metrics for each village and interaction type, that can be put into its own dataframe. The thought behind this is that I can pair this with the demographic data for each person/house and see how well the demographic data given can predict various network characteristics/hierarchies/positions within the networks.\n",
    "\n",
    "For example, one potential (unproven outcome) would be that households with roof type 3 are more likely to have (or do have) a higher betweenness centrality than other households in the village. Once the functions are defined to organize this data, I can train some machine learning algorithms on the data to see how well this fits.\n",
    "\n",
    "**A note: The term complex networks doesn't refer to the subject being difficult to understand (though it can be!), it refers to the organization of the networks themselves. A 'complex network' has certain characteristics, as defined by Wikipedia these are:**\n",
    "\n",
    "*In the context of network theory, a complex network is a graph (network) with non-trivial topological features—features that do not occur in simple networks such as lattices or random graphs but often occur in graphs modelling of real systems.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Code Button\n",
    "\n",
    "First, below is a javascript function written within HTML that, when rendered, will allow the user to either show the code or hide the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary library packages to render HTML in a code cell\n",
    "from IPython.display import HTML\n",
    "\n",
    "#Define the javascript function and HTML to produce the show/hide code button\n",
    "text = str('''\n",
    "    <script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <script>\n",
       "  function code_toggle() {\n",
       "    if (code_shown){\n",
       "      $('div.input').hide('500');\n",
       "      $('#toggleButton').val('Show Code')\n",
       "    } else {\n",
       "      $('div.input').show('500');\n",
       "      $('#toggleButton').val('Hide Code')\n",
       "    }\n",
       "    code_shown = !code_shown\n",
       "  }\n",
       "\n",
       "  $( document ).ready(function(){\n",
       "    code_shown=false;\n",
       "    $('div.input').hide()\n",
       "  });\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving Into the Code\n",
    "\n",
    "### Importing Libraries and Initial Variables\n",
    "\n",
    "In the cell below, I begin by importing all of the necessary libraries to perform this analysis. The main notebooks used are pandas (for dataframe creation and manipulation), and networkx for working with the complex networks/graphs derived from the adjacency matrices in the files. Networkx, while not a sophisticated network graphing library, makes it very easy to work with the graphs and derive characteristics from them.\n",
    "\n",
    "There is no output from the cell below, just initialization of the file paths and data types of the resulting dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######========> Import libraries needed for this notebook\n",
    "\n",
    "import numpy as np #Linear algebra library\n",
    "import pandas as pd #Data manipulation library\n",
    "import matplotlib.pyplot as plt #Visualization library\n",
    "import seaborn as sns #Advanced visualization library\n",
    "import os #Libary to reference file paths\n",
    "import re #Regular expressions library\n",
    "import datetime #Library I am using to estimate time remaining for chunks of code\n",
    "pd.set_option('display.multi_sparse', False) #Set so that full pandas multi-index is displayed\n",
    "import networkx as nx #Library used to analyze and view complex networks/graphs\n",
    "import warnings #Set so that warnings are not displayed\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "#######========>End library imports, begin code\n",
    "\n",
    "#######========>Set file paths for each directory that the files are located in\n",
    "\n",
    "#Set file path name string for the adjanceny matrices\n",
    "adj_path = os.getcwd() + '/datav4.0/Data/1. Network Data/Adjacency Matrices/'\n",
    "\n",
    "#Set the file path name string for the adjacency matrix keys\n",
    "adj_key_path = os.getcwd() + '/datav4.0/Data/1. Network Data/Adjacency Matrix Keys/'\n",
    "\n",
    "#Set the file path name string for the Demographics and Outcomes files\n",
    "dem_path = os.getcwd() + '/datav4.0/Data/2. Demographics and Outcomes/'\n",
    "\n",
    "#######========>End file path decleration\n",
    "\n",
    "#Declare all of the python data types for each of the columns in the house demographic file\n",
    "house_dtypes = {'village' : str, 'adjmatrix_key' : str, 'HHnum_in_village' : str, 'hhid' : str,\n",
    "                'hohreligion' : str, 'castesubcaste' : str, 'rooftype1' : int, 'rooftype2' : int,\n",
    "                'rooftype3' : int, 'rooftype4' : int, 'rooftype5' : int, 'rooftypeoth' : str,\n",
    "                'room_no' : int, 'bed_no' : int, 'electricity' : str, 'latrine' : str,\n",
    "                'ownrent' : str, 'hhSurveyed' : int, 'leader' : int}\n",
    "\n",
    "#Declare all of the python data types for each of the columns in the individual demographic file\n",
    "indiv_dtypes = {'adjmatrix_key': str,'age': int,'caste': str,'educ': str,'electioncard': str,\n",
    "                'english': str,'hhid': str,'hindi': str,'kannada': str,'mothertongue': str,\n",
    "                'movecontact': str,'movecontact_hhid': str,'movecontact_name': str,\n",
    "                'movecontact_pid': str,'movecontact_res': str,'movereason': str,'native_district': str,\n",
    "                'native_name': str,'native_taluk': str,'native_type': str,'occupation': str,\n",
    "                'otherlang': str,'pid': str,'privategovt': str,'rationcard': str, \n",
    "                'rationcard_colour': str,'religion': str,'res_time_mths': float,'res_time_yrs': str,\n",
    "                'resp_gend': str,'resp_id': str,'resp_status': str,'savings': str,'savings_no': str,\n",
    "                'shg_no': str,'shgparticipate': str,'speakother': str,'subcaste': str,'tamil': str,\n",
    "                'telugu': str,'urdu': str,'village': str,'villagenative': str,'work_freq': float,\n",
    "                'work_freq_type': str,'work_outside': str,'work_outside_freq': str,'workflag': str}\n",
    "\n",
    "#Use pandas to read in the stata file of the household demographics\n",
    "house_dem = pd.read_stata(dem_path + 'household_characteristics.dta', preserve_dtypes = False)\n",
    "#Declare the data types for the house_dem dataframe using the above dictionary\n",
    "house_dem = house_dem.astype(house_dtypes)\n",
    "\n",
    "#Use pandas to read in the stata file of the household demographics\n",
    "indiv_dem = pd.read_stata(dem_path + 'individual_characteristics.dta', preserve_dtypes = False)\n",
    "#Declare the data types for the indiv_dem dataframe using the above dictionary\n",
    "indiv_dem = indiv_dem.astype(indiv_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are many hundreds of files, each with an adjacency matrix, I needed an effective way to organize all of them, and have a single entity where I could easily access each one. At first, I tried combining all of the dataframes into one, but this had several shortcomings and was not a tractable method.\n",
    "\n",
    "So what I ended up doing was creating a dictionary of pandas dataframes. Each key of the dictionary is the adjusted filename (without the '.csv'), and each value of the dictionary is the corresponding adjacency matrix.\n",
    "\n",
    "In the cell below, the only output is the time remaining I included to check how long this process was taking. The code below, to create the dictionary of dataframes, takes about 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time remaining: 4.82 minutes\n",
      "Time remaining: 4.59 minutes\n",
      "Time remaining: 4.36 minutes\n",
      "Time remaining: 3.41 minutes\n",
      "Time remaining: 2.88 minutes\n",
      "Time remaining: 2.43 minutes\n",
      "Time remaining: 1.49 minutes\n",
      "Time remaining: 0.89 minutes\n"
     ]
    }
   ],
   "source": [
    "#######========>Use to calculate estimated time remaining\n",
    "\n",
    "a = datetime.datetime.now()\n",
    "count, last_time = 0, 0\n",
    "\n",
    "#######========>End time remaining variables\n",
    "\n",
    "#######========>Declare dicitionary and list variables\n",
    "\n",
    "adj_dfs = {} #Store all of the adjacency matrix dataframes in a dictionary\n",
    "adj_names = [] #Store all of the adjacency matrix file names in a list\n",
    "\n",
    "#######========>End variable decleration, begin looping through files\n",
    "\n",
    "files = os.listdir(adj_path)\n",
    "files.remove('.DS_Store')\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "#######========>Cast each adjacency matrix to a dataframe, stored in a dictionary of dataframes    \n",
    "    \n",
    "    #Get rid of filename extension to create filename to be stored\n",
    "    filename = str(file.replace('.csv','').replace('adj_',''))\n",
    "    \n",
    "    #Add name of the file to list of file names\n",
    "    adj_names.append(filename)\n",
    "    \n",
    "    #Create dataframe and cast to dictionary\n",
    "    adj_dfs[filename] = pd.read_csv(adj_path + file, header = None)\n",
    "\n",
    "#######========>End casting of dataframe to dictionary on this iteration\n",
    "    \n",
    "#######========>Create new columns with file characteristics and reorder and reindex as needed\n",
    "\n",
    "    #Create village number column\n",
    "    adj_dfs[filename]['Village'] = str(re.findall('\\d+', filename)[0])\n",
    "    \n",
    "    #Create type column, can be house or individual\n",
    "    adj_dfs[filename]['Type'] = (lambda x: 'Person' if not re.findall('HH', x) else 'House')(filename)\n",
    "    \n",
    "    #Create activity column, used to show how the people are interacting, i.e. going to temple\n",
    "    adj_dfs[filename]['Activity'] = (lambda x: x[0:x.index('_')])(filename)\n",
    "    \n",
    "    #Add the village and type columns to the index\n",
    "    adj_dfs[filename].set_index(['Village','Type'], append = True, inplace = True)\n",
    "    \n",
    "    #Set the Activity column to column position 0 in the DataFrame\n",
    "    for column in ['Activity']:\n",
    "        holder = adj_dfs[filename][column]\n",
    "        adj_dfs[filename].drop(labels = [column], axis = 1, inplace = True)\n",
    "        adj_dfs[filename].insert(0, column, holder)\n",
    "    \n",
    "#######========>End reordering and reindexing\n",
    "    \n",
    "#######========>Used to calculate estimated time remaining in the cell. Not relevant code\n",
    "\n",
    "    count += 1\n",
    "    if count%250 == 0:\n",
    "        b = datetime.datetime.now()\n",
    "        time_remaining = ((b-a).total_seconds()*(len(os.listdir(adj_path))/count) - last_time)/60\n",
    "        print('Time remaining: ' + str(round(time_remaining, 2)) + ' minutes')\n",
    "        last_time = (b-a).total_seconds()\n",
    "        \n",
    "#######========>END not time remaining relevant code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing on the same vein, the cell below does the same process as above, except it does it for the keys corresponding to the indices in the adjacency matrices. This is necessary as I will merge the keys, village numbers, activity, and category so that the adjacency matrix characteristics can be paired with the demographic data.\n",
    "\n",
    "The cell below doesn't output anything, it just creates the dictionary of key dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######========>Declare dicitionary and list variables\n",
    "\n",
    "key_dfs = {} #Store all of the adjacency key matrix dataframes in a dictionary\n",
    "key_names = [] #Store all of the adjacency key matrix filenames in a list\n",
    "\n",
    "#######========>End variable decleration, begin looping through files\n",
    "\n",
    "files = os.listdir(adj_key_path)\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "#######========>Cast each adjacency key matrix to a dataframe, stored in a dictionary of dataframes\n",
    "    \n",
    "    #Get rid of filename extension to create filename to be stored\n",
    "    filename = str(file.replace('.csv',''))\n",
    "    \n",
    "    #Add name of the file to list of file names\n",
    "    key_names.append(filename)\n",
    "    \n",
    "    #Create dataframe and cast to dictionary\n",
    "    key_dfs[filename] = pd.read_csv(adj_key_path + file, header = None, names = ['Key'])\n",
    "    \n",
    "#######========>End casting of dataframe to dictionary on this iteration\n",
    "\n",
    "#######========>Create new columns with file characteristics and reorder and reindex as needed\n",
    "\n",
    "    #Create village number column\n",
    "    key_dfs[filename]['Village'] = str(re.findall('\\d+', filename)[0])\n",
    "    \n",
    "    #Create type column, can be house or individual\n",
    "    key_dfs[filename]['Type'] = (lambda x: 'Person' if not re.findall('HH', x) else 'House')(filename)\n",
    "    \n",
    "    #Add the village and type columns to the index\n",
    "    key_dfs[filename].set_index(['Village','Type'], append = True, inplace = True)\n",
    "    \n",
    "#######========>End reordering and reindexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below creates a dataframe of file names corresponding to each combination of village, activity, and category (house/person). This is helpful so that it is possible to get an adjacency matrix from the dataframe by knowing the village, activity, and category, without having to memorize the way the filenames are structured.\n",
    "\n",
    "This cell outputs the first 10 lines of this dataframe, called adj_nameframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj_Name</th>\n",
       "      <th>Village</th>\n",
       "      <th>Type</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Key_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allVillageRelationships_HH_vilno_1</td>\n",
       "      <td>1</td>\n",
       "      <td>House</td>\n",
       "      <td>allVillageRelationships</td>\n",
       "      <td>key_HH_vilno_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allVillageRelationships_HH_vilno_10</td>\n",
       "      <td>10</td>\n",
       "      <td>House</td>\n",
       "      <td>allVillageRelationships</td>\n",
       "      <td>key_HH_vilno_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allVillageRelationships_HH_vilno_11</td>\n",
       "      <td>11</td>\n",
       "      <td>House</td>\n",
       "      <td>allVillageRelationships</td>\n",
       "      <td>key_HH_vilno_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allVillageRelationships_HH_vilno_12</td>\n",
       "      <td>12</td>\n",
       "      <td>House</td>\n",
       "      <td>allVillageRelationships</td>\n",
       "      <td>key_HH_vilno_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allVillageRelationships_HH_vilno_14</td>\n",
       "      <td>14</td>\n",
       "      <td>House</td>\n",
       "      <td>allVillageRelationships</td>\n",
       "      <td>key_HH_vilno_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>allVillageRelationships_HH_vilno_15</td>\n",
       "      <td>15</td>\n",
       "      <td>House</td>\n",
       "      <td>allVillageRelationships</td>\n",
       "      <td>key_HH_vilno_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>allVillageRelationships_HH_vilno_16</td>\n",
       "      <td>16</td>\n",
       "      <td>House</td>\n",
       "      <td>allVillageRelationships</td>\n",
       "      <td>key_HH_vilno_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allVillageRelationships_HH_vilno_17</td>\n",
       "      <td>17</td>\n",
       "      <td>House</td>\n",
       "      <td>allVillageRelationships</td>\n",
       "      <td>key_HH_vilno_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>allVillageRelationships_HH_vilno_18</td>\n",
       "      <td>18</td>\n",
       "      <td>House</td>\n",
       "      <td>allVillageRelationships</td>\n",
       "      <td>key_HH_vilno_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>allVillageRelationships_HH_vilno_19</td>\n",
       "      <td>19</td>\n",
       "      <td>House</td>\n",
       "      <td>allVillageRelationships</td>\n",
       "      <td>key_HH_vilno_19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Adj_Name Village   Type  \\\n",
       "0   allVillageRelationships_HH_vilno_1       1  House   \n",
       "1  allVillageRelationships_HH_vilno_10      10  House   \n",
       "2  allVillageRelationships_HH_vilno_11      11  House   \n",
       "3  allVillageRelationships_HH_vilno_12      12  House   \n",
       "4  allVillageRelationships_HH_vilno_14      14  House   \n",
       "5  allVillageRelationships_HH_vilno_15      15  House   \n",
       "6  allVillageRelationships_HH_vilno_16      16  House   \n",
       "7  allVillageRelationships_HH_vilno_17      17  House   \n",
       "8  allVillageRelationships_HH_vilno_18      18  House   \n",
       "9  allVillageRelationships_HH_vilno_19      19  House   \n",
       "\n",
       "                  Activity         Key_Name  \n",
       "0  allVillageRelationships   key_HH_vilno_1  \n",
       "1  allVillageRelationships  key_HH_vilno_10  \n",
       "2  allVillageRelationships  key_HH_vilno_11  \n",
       "3  allVillageRelationships  key_HH_vilno_12  \n",
       "4  allVillageRelationships  key_HH_vilno_14  \n",
       "5  allVillageRelationships  key_HH_vilno_15  \n",
       "6  allVillageRelationships  key_HH_vilno_16  \n",
       "7  allVillageRelationships  key_HH_vilno_17  \n",
       "8  allVillageRelationships  key_HH_vilno_18  \n",
       "9  allVillageRelationships  key_HH_vilno_19  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######========>Create dataframe of the adjacency matrix filenames and their corresponding characteristics\n",
    "\n",
    "#Create dataframe of the adjacency matrix filenames\n",
    "adj_nameframe = pd.DataFrame(adj_names, columns = ['Adj_Name'])\n",
    "\n",
    "#Add village number column\n",
    "adj_nameframe['Village'] = adj_nameframe['Adj_Name'].apply(lambda x: str(re.findall('\\d+', x)[0]))\n",
    "\n",
    "#Add type column\n",
    "adj_nameframe['Type'] = adj_nameframe['Adj_Name'].apply(lambda x: 'Person' if not re.findall('HH', x) else 'House')\n",
    "\n",
    "#Add activity column\n",
    "adj_nameframe['Activity'] = adj_nameframe['Adj_Name'].apply(lambda x: x[0:x.index('_')])\n",
    "\n",
    "#######========>End creation of dataframe for filenames\n",
    "\n",
    "#######========>Create dataframe of filenames for the adjacency key matrices\n",
    "\n",
    "#Create dataframe of the key file names\n",
    "key_nameframe = pd.DataFrame(key_names, columns = ['Key_Name'])\n",
    "\n",
    "#Add village number column\n",
    "key_nameframe['Village'] = key_nameframe['Key_Name'].apply(lambda x: str(re.findall('\\d+', x)[0]))\n",
    "\n",
    "#Add type column\n",
    "key_nameframe['Type'] = key_nameframe['Key_Name'].apply(lambda x: 'Person' if not re.findall('HH', x) else 'House')\n",
    "\n",
    "#######========>End creation of dataframe for the key filenames\n",
    "\n",
    "#######========>Merge the two dataframes together so that the files can be referenced relative to each other\n",
    "\n",
    "#Merge the two on village number and type (what makes them unique), so the two can be accessed from each other\n",
    "adj_nameframe = pd.merge(adj_nameframe, key_nameframe, how = 'left', on = ['Village','Type'])\n",
    "\n",
    "adj_nameframe.head(10)\n",
    "\n",
    "#######========>End by displaying the first 10 rows of the resulting dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, I combined the key information with the adjacency matrices. The resulting dataframe will have the village, key number, activity, and category as its indices. This information needs to be in the index rather than as columns so that the values of the dataframe are still a square adjacency matrix that can be read into a graph easily.\n",
    "\n",
    "A new dictionary, called combined_dfs, will be created, with the adjusted filename as the key, and the combined dataframe as the value.\n",
    "\n",
    "The output of the cell, in addition to displaying the time remaining throughout the iteration, is the first 10 rows of one of the dataframes in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time remaining: 1.08 minutes\n",
      "Time remaining: 0.97 minutes\n",
      "Time remaining: 0.89 minutes\n",
      "Time remaining: 0.72 minutes\n",
      "Time remaining: 0.6 minutes\n",
      "Time remaining: 0.49 minutes\n",
      "Time remaining: 0.32 minutes\n",
      "Time remaining: 0.19 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Village</th>\n",
       "      <th>Type</th>\n",
       "      <th>Key</th>\n",
       "      <th>Activity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>House</th>\n",
       "      <th>1</th>\n",
       "      <th>allVillageRelationships</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>House</th>\n",
       "      <th>2</th>\n",
       "      <th>allVillageRelationships</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>House</th>\n",
       "      <th>3</th>\n",
       "      <th>allVillageRelationships</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>House</th>\n",
       "      <th>4</th>\n",
       "      <th>allVillageRelationships</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>House</th>\n",
       "      <th>5</th>\n",
       "      <th>allVillageRelationships</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0    1    2    3    4    5    \\\n",
       "  Village Type  Key Activity                                                \n",
       "0 1       House 1   allVillageRelationships    0    1    0    0    0    0   \n",
       "1 1       House 2   allVillageRelationships    1    0    1    1    0    0   \n",
       "2 1       House 3   allVillageRelationships    0    1    0    0    0    0   \n",
       "3 1       House 4   allVillageRelationships    0    1    0    0    0    0   \n",
       "4 1       House 5   allVillageRelationships    0    0    0    0    0    1   \n",
       "\n",
       "                                             6    7    8    9   ...   172  \\\n",
       "  Village Type  Key Activity                                    ...         \n",
       "0 1       House 1   allVillageRelationships    0    0    0    0 ...     0   \n",
       "1 1       House 2   allVillageRelationships    0    0    0    0 ...     0   \n",
       "2 1       House 3   allVillageRelationships    0    0    0    0 ...     0   \n",
       "3 1       House 4   allVillageRelationships    0    0    0    0 ...     0   \n",
       "4 1       House 5   allVillageRelationships    0    1    0    0 ...     0   \n",
       "\n",
       "                                             173  174  175  176  177  178  \\\n",
       "  Village Type  Key Activity                                                \n",
       "0 1       House 1   allVillageRelationships    0    0    0    0    0    0   \n",
       "1 1       House 2   allVillageRelationships    0    0    0    0    0    0   \n",
       "2 1       House 3   allVillageRelationships    0    0    0    0    0    0   \n",
       "3 1       House 4   allVillageRelationships    0    0    0    0    0    0   \n",
       "4 1       House 5   allVillageRelationships    0    0    0    0    0    0   \n",
       "\n",
       "                                             179  180  181  \n",
       "  Village Type  Key Activity                                \n",
       "0 1       House 1   allVillageRelationships    0    0    0  \n",
       "1 1       House 2   allVillageRelationships    0    0    0  \n",
       "2 1       House 3   allVillageRelationships    0    0    0  \n",
       "3 1       House 4   allVillageRelationships    0    0    0  \n",
       "4 1       House 5   allVillageRelationships    0    0    0  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######========>Use to calculate estimated time remaining\n",
    "\n",
    "a = datetime.datetime.now()\n",
    "count, last_time = 0, 0\n",
    "\n",
    "#######========>End time remaining variables\n",
    "\n",
    "#######========>Declare dicitionary and list variables\n",
    "\n",
    "combined_dfs = {} #Store all of the adjacency matrix dataframes with key values in a dictionary\n",
    "\n",
    "#######========>End variable decleration, begin looping through files and merging\n",
    "\n",
    "for file in adj_nameframe['Adj_Name']:\n",
    "    \n",
    "    key_file = adj_nameframe[adj_nameframe.Adj_Name == file]['Key_Name'].values[0]\n",
    "    combined_dfs[file] = pd.merge(adj_dfs[file], key_dfs[key_file], how = 'left',\n",
    "                                  left_index = True, right_index = True)\n",
    "    \n",
    "    combined_dfs[file]['Key'] = combined_dfs[file][combined_dfs[file].Key.notnull()]['Key'].astype(int).astype(str)\n",
    "    \n",
    "    combined_dfs[file].set_index(['Key','Activity'], append = True, inplace = True)\n",
    "    \n",
    "#######========>Used to calculate estimated time remaining in the cell. Not relevant code\n",
    "\n",
    "    count += 1\n",
    "    if count%250 == 0:\n",
    "        b = datetime.datetime.now()\n",
    "        time_remaining = ((b-a).total_seconds()*(len(os.listdir(adj_path))/count) - last_time)/60\n",
    "        print('Time remaining: ' + str(round(time_remaining, 2)) + ' minutes')\n",
    "        last_time = (b-a).total_seconds()\n",
    "        \n",
    "#######========>END not time remaining relevant code\n",
    "\n",
    "combined_dfs[adj_names[0]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Functions\n",
    "\n",
    "Now that the data is neatly organized into a dictionary of dataframes that can be easily called, I will begin to define a series of functions to get analyzable data from the complex networks. None of these graph definitions will output anything before being called, so if you have clicked the button to hide the code, you won't see the functions. I will however, briefly explain what each does in the cell directly above it.\n",
    "\n",
    "The first function defined below, called 'graph', generates a networkx graph from a given set of attributes (village, category, activity), and returns the graph object along with a couple characteristics, and dictionaries to map the nodes to the correct keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get the graph, connected subgraph and percentage of degree zero nodes\n",
    "def graph(attributes):\n",
    "    \n",
    "    #Enumerate the list of attributes, which is a list of size three, including the below attributes\n",
    "    Village = attributes[0]\n",
    "    Category = attributes[1]\n",
    "    Activity = attributes[2]\n",
    "    \n",
    "    #Define the file name for the criteria given in the function\n",
    "    graph_name = adj_nameframe[(adj_nameframe.Village == Village)&\n",
    "                 (adj_nameframe.Type == Category)&\n",
    "                 (adj_nameframe.Activity == Activity)]['Adj_Name'].values[0]\n",
    "    \n",
    "    #Define a conditional that calls the correct dataframe to pull the labels frame (house or indiv)\n",
    "    if Category == 'Person':\n",
    "        \n",
    "        #Pull the section of the individual demographic dataframe that is equal to the current village\n",
    "        label_frame = indiv_dem[indiv_dem.village == Village]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        #Pull the section of the household demographic dataframe that is equal to the current village\n",
    "        label_frame = house_dem[house_dem.village == Village]\n",
    "    \n",
    "    #Call the dataframe in the combined_dfs dictionary corresponding to the pulled filename\n",
    "    df = combined_dfs[graph_name]\n",
    "    #Initialize the graph from the adjacency matrix that includes all the nodes for the filename\n",
    "    G = nx.Graph(df.values)\n",
    "    \n",
    "    #Define a list of keys, categories, and activities that correspond the the indices of the current dataframe\n",
    "    keys = list(df.index.get_level_values('Key'))\n",
    "    categories = list(df.index.get_level_values('Type'))\n",
    "    activities = list(df.index.get_level_values('Activity'))\n",
    "    \n",
    "    #Define a list of all nodes of the graph\n",
    "    nodes = list(G.nodes())\n",
    "    \n",
    "    #Create dictionaries for mapping the list of nodes to the keys, categories, and activities for this graph\n",
    "    key_dict = {nodes[i] : keys[i] for i in range(len(nodes))}\n",
    "    cat_dict = {nodes[i] : categories[i] for i in range(len(nodes))}\n",
    "    act_dict = {nodes[i] : activities[i] for i in range(len(nodes))}\n",
    "    \n",
    "    #Use those mapping dictionaries to set the Keys, Type, and Activity as node attributes\n",
    "    nx.set_node_attributes(G, key_dict, 'Keys')\n",
    "    nx.set_node_attributes(G, cat_dict, 'Type')\n",
    "    nx.set_node_attributes(G, act_dict, 'Activity')\n",
    "    \n",
    "    #Define the number of nodes in the full graph\n",
    "    num_nodes = G.order()\n",
    "    \n",
    "    #Define the number of edges in the full graph\n",
    "    num_edges = G.size()\n",
    "    \n",
    "    #Define a list of degree zero nodes and get the number\n",
    "    isolates = list(nx.isolates(G))\n",
    "    num_isolates = len(isolates)\n",
    "    \n",
    "    #Calculate the percentage of degree zero nodes in the graph\n",
    "    pct_isolates = num_isolates/num_nodes\n",
    "    \n",
    "    #Put all of the relevant calculations/characteristics into a \n",
    "    output = {'graph' : G, 'nodes' : num_nodes, \n",
    "              'edges' : num_edges, 'label frame' : label_frame,\n",
    "              'pct_isolates' : pct_isolates, 'frame' : df,\n",
    "              'keys' : key_dict, 'type' : cat_dict, 'activity' : act_dict}\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function, called 'multi_values', creates a dictionary of the outputs of all the algorithms that return a unique value for each node in the graph (or connected subgraph if the graph is not connected). \n",
    "\n",
    "There is no output for the cell below, it is just used to return a dictionary when called in other functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines a function that takes in a fully connected graph/sub graph and returns a dictionary of outputs\n",
    "def multi_values(G):\n",
    "    \n",
    "    #Define the average shortest path length per node, rather than for the entire graph\n",
    "    shortest_path = dict(nx.shortest_path_length(G))\n",
    "    shortest_path = {k : np.mean([j for i,j in v.items() if i != k]) for k,v in shortest_path.items()}\n",
    "    \n",
    "    #Conditional for if the power iteration can't converge in max_iter, use the numpy version\n",
    "    def eig(G):\n",
    "        try:\n",
    "            return nx.eigenvector_centrality(G)\n",
    "        except:\n",
    "            return nx.eigenvector_centrality_numpy(G)\n",
    "    \n",
    "    #Define a dictionary that maps algorithm names to their outputs for G\n",
    "    multi = {'betweenness centrality' : nx.betweenness_centrality(G),\n",
    "             'eigenvector centrality' : eig(G),\n",
    "             'shortest path' : shortest_path,\n",
    "             'clustering' : nx.clustering(G),\n",
    "             'closeness centrality' : nx.closeness_centrality(G),\n",
    "             'katz centrality' : nx.katz_centrality_numpy(G),\n",
    "             'load centrality' : nx.load_centrality(G),\n",
    "             'eccentricity' : nx.eccentricity(G), \n",
    "             'degrees' : dict(G.degree()),\n",
    "             'triangles' : nx.triangles(G),\n",
    "             'square clustering' : nx.square_clustering(G),\n",
    "             'subgraph centrality' : nx.subgraph_centrality(G)}\n",
    "    \n",
    "    #Return the dictionary\n",
    "    return multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the function above, the function single_values creates a dictionary of outputs that pertain to the entire graph (connected subgraph if the graph is not connected). \n",
    "\n",
    "There is no output from this cell, but the function is called in other functions to return the desired values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_values(G):\n",
    "    \n",
    "    #Define a function that returns whether the component is an isolate within the greater graph\n",
    "    def is_isolate(G):\n",
    "        \n",
    "        #Conditional for if the number of nodes is equal to 1 (i.e. is an isolate)\n",
    "        if G.order() == 1:\n",
    "            return \"Yes\"\n",
    "        else:\n",
    "            return \"No\"\n",
    "        \n",
    "    #Define a dictionary that maps algorithm names to their outputs for G\n",
    "    single = {'diameter' : nx.diameter(G),\n",
    "              'avg shortest path' : nx.average_shortest_path_length(G),\n",
    "              'avg clustering' : nx.average_clustering(G),\n",
    "              'wiener index' : nx.wiener_index(G),\n",
    "              'radius' : nx.radius(G), \n",
    "              'density' : nx.density(G), \n",
    "              'transitivity' : nx.transitivity(G),\n",
    "              'estrada index' : nx.estrada_index(G),\n",
    "              'Edges' : G.size(), 'Nodes' : G.order(),\n",
    "              'Isolate' : is_isolate(G)}\n",
    "    \n",
    "    return single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below, make_frames, takes in a single graph as input and creates two dataframes, one for the algorithm outputs pertaining to each node, and one for the ouptuts pertaining to the entire graph. It does this by looping through all of the connected subgraphs, and calling the multi_values and single_values functions for each subgraph. After getting the dictionaries for each connected subgraph, the function converts the dicts to dataframes then concatenates them together.\n",
    "\n",
    "The cell below has no output, but it can be called on its own, and is also called by the all_files function, returning the dataframes for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frames(G, attributes):\n",
    "    \n",
    "    #Initialize a dictionary containing the mapping from the node values to the key values\n",
    "    keys = pd.DataFrame.from_dict(nx.get_node_attributes(G, 'Keys'), orient = 'index', dtype = str)\n",
    "    \n",
    "    #Name the Keys columns appropriately\n",
    "    keys.reset_index(inplace = True)\n",
    "    keys.rename(columns = {0 : 'Keys', 'index' : 'Node_Num'}, inplace = True)\n",
    "    \n",
    "    #Initialize the attributes specific to this file\n",
    "    Village = attributes[0] #The village number\n",
    "    Category = attributes[1] #The category (House/Person)\n",
    "    Activity = attributes[2] #The interaction type/activity interaction recorded on\n",
    "    \n",
    "    #Initialize a list of attribute names, so that they can be entered as columns in the dataframes\n",
    "    names = ['Village','Type','Activity']\n",
    "    \n",
    "    #Initialize empty dictionaries for the connected subgraph vlaues to be stored in\n",
    "    single_dfs = {}\n",
    "    multi_dfs = {}\n",
    "    \n",
    "    #Loop over the connected subgraphs of the graph for G\n",
    "    for i, component in enumerate(nx.connected_component_subgraphs(G)):\n",
    "        \n",
    "        nodes, edges = component.order(), component.size()\n",
    "    \n",
    "        #Call the single_values function to get a dictionary of single output values for the graph component\n",
    "        single = pd.DataFrame.from_dict(single_values(component), orient = 'index').transpose()\n",
    "        \n",
    "        #Call the multi_values function to get the dictionary of node specific values for the graph component\n",
    "        multi = pd.DataFrame.from_dict(multi_values(component))\n",
    "        \n",
    "        #Append node and edge numbers to the multi value dataframe\n",
    "        multi['Nodes'] = nodes\n",
    "        multi['Edges'] = edges\n",
    "        \n",
    "        #Loop over the list of attribute names to create new columns for the current dataframes\n",
    "        for j, name in enumerate(names):\n",
    "            single[name] = attributes[j]\n",
    "            multi[name] = attributes[j]\n",
    "        \n",
    "        #Append the single values dataframe to the single_dfs dictionary\n",
    "        single_dfs[str(i)] = single\n",
    "        \n",
    "        #Append the multi values dataframe to the multi_dfs dictionary\n",
    "        multi_dfs[str(i)] = multi\n",
    "        \n",
    "        \n",
    "    #Cocatenate all of the connected subgraph single values dataframes into one so all nodes are present\n",
    "    single_df = pd.concat(single_dfs.values(), ignore_index = True)\n",
    "    \n",
    "    #Cocatenate all of the connected subgraph multi values dataframes into one so all nodes are present\n",
    "    multi_df = pd.concat(multi_dfs.values())\n",
    "    \n",
    "    \n",
    "    #Merge the keys dataframe to assign each of the node index values to the key present in the demographic frame\n",
    "    multi_df = multi_df.merge(keys, how = 'left', left_index = True, right_on = 'Node_Num')\n",
    "    \n",
    "    return single_df, multi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below, called all_files, loops through either a specified number of files, or all the files in the adj_nameframe. For each file, it calls the make_frames function, and then concatenates each of the created dataframes into one each for the multiple value outputs and one for the singular value outputs. \n",
    "\n",
    "The goal of this function is to create a single dataframe that can be merged with the house demographic and individual demographic data for each person/house in each village. Once this is done, analysis can be done to see if any of the demographic characteristics are correlated with characteristics of the resulting complex networks.\n",
    "\n",
    "The cell below doesn't return any output, but when called it will print a time remaining string that gives an estimate of time remaining for every 25 files iterated through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_files(num_files = 'all'):\n",
    "    \n",
    "    #Initialize variables to calculate how much time is remaining\n",
    "    a = datetime.datetime.now()\n",
    "    count, last_time = 0, 0\n",
    "    \n",
    "    #Initialize empty dictionaries to store the dataframes as the file names are iterated over\n",
    "    single_dfs, multi_dfs = {}, {}\n",
    "    \n",
    "    #Define a conditional that decides whether to include a slice of the files or all of them\n",
    "    if num_files == 'all':\n",
    "        #Define the full list of file names to loop through\n",
    "        files = list(adj_nameframe.Adj_Name.unique())\n",
    "        num_iter = len(files)\n",
    "        \n",
    "    else:\n",
    "        #Define a partial slice of all the file names to loop through\n",
    "        files = list(adj_nameframe.Adj_Name.unique())[:num_files]\n",
    "        num_iter = num_files\n",
    "    \n",
    "    #Loop over the predefined number of files\n",
    "    for file in files:\n",
    "        \n",
    "        #Define the village, category, and activity, then store in a list to initialize the graph\n",
    "        Village = str(adj_nameframe[adj_nameframe.Adj_Name == file]['Village'].values[0])\n",
    "        Category = str(adj_nameframe[adj_nameframe.Adj_Name == file]['Type'].values[0])\n",
    "        Activity = str(adj_nameframe[adj_nameframe.Adj_Name == file]['Activity'].values[0])\n",
    "        attributes = [Village, Category, Activity]\n",
    "        \n",
    "        #Use the attributes list defined above to pass into the graph function\n",
    "        output = graph(attributes)\n",
    "        \n",
    "        #Get the full graph from the dictionary returned by the graph function\n",
    "        G = output['graph']\n",
    "        \n",
    "        #Use the make_frames function to make a concatenated dataframe for all components of the graph\n",
    "        s_df, m_df = make_frames(G, attributes)\n",
    "        \n",
    "        #Store both the single value and multi value dataframes in dictionaries\n",
    "        single_dfs[file] = s_df\n",
    "        multi_dfs[file] = m_df\n",
    "        \n",
    "        #Set up the timing variables to print the time remaining every 25th iteration\n",
    "        count += 1\n",
    "        if count%25 == 1:\n",
    "            b = datetime.datetime.now()\n",
    "            time_remaining = ((b-a).total_seconds()*(num_iter/count) - last_time)/60\n",
    "            print('Time remaining: ' + str(round(time_remaining, 2)) + ' minutes')\n",
    "            last_time = (b-a).total_seconds()\n",
    "    \n",
    "    #After the iteration is finished, concatenate each of the single values dataframes into one\n",
    "    single_df = pd.concat(single_dfs.values(), ignore_index = True)\n",
    "    \n",
    "    #After the iteration is finished, concatenate each of the multi values dataframes into one\n",
    "    multi_df = pd.concat(multi_dfs.values(), ignore_index = True)\n",
    "    \n",
    "    #Return the fully concatenated dataframes\n",
    "    return single_df, multi_df\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of the necessary functions defined, I can now loop through the files and create the single value dataframe and multi value dataframe. This will take a significant amount of time, but once it is done I can write them each to csv's. With the resulting data stored in csv's, all I will need to do when I restart the notebook is load these csv's along with the demographic data, so this process only needs to be done once.\n",
    "\n",
    "The cell below will only output the time remaining estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time remaining: 131.27 minutes\n",
      "Time remaining: 145.98 minutes\n",
      "Time remaining: 155.53 minutes\n",
      "Time remaining: 192.12 minutes\n",
      "Time remaining: 963.85 minutes\n",
      "Time remaining: 1383.71 minutes\n"
     ]
    }
   ],
   "source": [
    "#Call the all files function, and store the outputs as single_df and multi_df\n",
    "single_df, multi_df = all_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After each of the graphs' characteristics are combined into a dataframe, I can write them to csv's.\n",
    "\n",
    "In the cells below, I have displayed the first 10 rows of the each of the single/multi value dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display first 10 rows of the multi value dataframe\n",
    "multi_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the first 10 rows of the single value dataframe\n",
    "single_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below doesn't output anything, it just writes the dataframes to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write each of the dataframes to csv files for subsequent import and restarting notebook at this point\n",
    "multi_df.to_csv('multi_value.csv', index = False)\n",
    "single_df.to_csv('single_value.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is for visualizing the graph of one of the adjacency matrices. It can take in some of the graph characteristics, such as eigenvector centrality, and use it to distort the sizes/colors of the nodes, for example.\n",
    "\n",
    "The graphing programs come from graphviz, which networkx can use. The function doesn't return anything, but it will display a graph when it is finished. The title of the graph will be the graphviz program name.\n",
    "\n",
    "The cell below just defines the function, and doesn't have an ouput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define graph to display the connected graph with distortion based on desired centrality measure\n",
    "def graph_with_distortion(G, summary, label_frame, size = None, \n",
    "                          with_labels = False, labels = None, \n",
    "                          node_color = None, node_map = None,\n",
    "                          prog = 'neato',label = None):\n",
    "    \n",
    "    #Conditional for deciding what the size_list passed into the graph function will be\n",
    "    if size:\n",
    "        \n",
    "        #Define the list of sizes from the measure in the summary dictionary\n",
    "        size_list = list(summary[size].values())\n",
    "    \n",
    "        #Scale the size list so it is appropriate for the graph\n",
    "        size_list = [(300.0/np.mean(size_list))*x for x in size_list]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        #If no size metric is passed, set the size_list to be passed to none\n",
    "        size_list = None\n",
    "        \n",
    "    #Define a conditional that determines what to make the color passed into the graph function\n",
    "    if node_color:\n",
    "        \n",
    "        #Color takes on the values of the metric passed as node_color\n",
    "        color = list(summary[node_color].values())\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        #No color values are passed\n",
    "        color = None\n",
    "    \n",
    "    #Define a conditional to map the desired node labels to the nodes in the graph\n",
    "    if labels:\n",
    "        \n",
    "        #Use the label_frame passed into the function and map from node numbers\n",
    "        label_dict = label_frame.set_index('adjmatrix_key')[labels].to_dict()\n",
    "        label_dict = {int(k) : v for k,v in label_dict.items() if int(k) in list(G.nodes)}\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        #If labels is none, pass none\n",
    "        label_dict = None\n",
    "    \n",
    "    #Define the position based on the available graphviz programs\n",
    "    pos = nx.drawing.nx_agraph.graphviz_layout(G, prog = prog)\n",
    "    \n",
    "    #Create a matplotlib figure\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    #Define the title to be the Graphviz program used\n",
    "    plt.title(prog)\n",
    "    \n",
    "    #Use the draw spring algorithm from networkx to draw the network\n",
    "    nx.draw_networkx(G, with_labels = with_labels, node_color = color,\n",
    "                     cmap = node_map, labels = label_dict, \n",
    "                     node_size = size_list, pos = pos, label = label)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below, loops through two of the graphviz graphing programs, and displays both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "progs = ['neato', 'dot']\n",
    "for prog in progs:\n",
    "    graph_with_distortion(G, summary, label_frame, node_map = plt.cm.Reds, \n",
    "                          node_color = 'eigenvector centrality', prog = prog, label = prog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
